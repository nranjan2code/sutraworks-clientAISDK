import type { ExtendedModelInfo } from '../../types';

export const ollamaModels: ExtendedModelInfo[] = [
    // Llama 4 (requires Ollama 0.6+)
    {
        id: 'llama4-scout',
        name: 'Llama 4 Scout',
        provider: 'ollama',
        type: 'chat',
        context_window: 10000000,
        supports_vision: true,
        supports_tools: true,
        supports_streaming: true,
        description: 'Local 109B MoE model - requires Ollama',
    },
    // Llama 3.x
    {
        id: 'llama3.3',
        name: 'Llama 3.3',
        provider: 'ollama',
        type: 'chat',
        context_window: 128000,
        supports_vision: false,
        supports_tools: true,
        supports_streaming: true,
        description: 'Local model - requires Ollama',
    },
    {
        id: 'llama3.2',
        name: 'Llama 3.2',
        provider: 'ollama',
        type: 'chat',
        context_window: 128000,
        supports_vision: true,
        supports_tools: true,
        supports_streaming: true,
        description: 'Local model with vision - requires Ollama',
    },
    {
        id: 'llama3.1',
        name: 'Llama 3.1',
        provider: 'ollama',
        type: 'chat',
        context_window: 128000,
        supports_vision: false,
        supports_tools: true,
        supports_streaming: true,
    },
    // Other local models
    {
        id: 'mistral',
        name: 'Mistral',
        provider: 'ollama',
        type: 'chat',
        context_window: 32768,
        supports_vision: false,
        supports_tools: false,
        supports_streaming: true,
    },
    {
        id: 'codellama',
        name: 'Code Llama',
        provider: 'ollama',
        type: 'chat',
        context_window: 16384,
        supports_vision: false,
        supports_tools: false,
        supports_streaming: true,
    },
    {
        id: 'qwen2.5',
        name: 'Qwen 2.5',
        provider: 'ollama',
        type: 'chat',
        context_window: 32768,
        supports_vision: false,
        supports_tools: true,
        supports_streaming: true,
    },
    {
        id: 'deepseek-r1',
        name: 'DeepSeek R1',
        provider: 'ollama',
        type: 'chat',
        context_window: 128000,
        supports_vision: false,
        supports_tools: true,
        supports_streaming: true,
        supports_reasoning: true,
        description: 'Local reasoning model - requires Ollama',
    },
    // Embeddings
    {
        id: 'nomic-embed-text',
        name: 'Nomic Embed Text',
        provider: 'ollama',
        type: 'embedding',
        context_window: 8192,
    },
    {
        id: 'mxbai-embed-large',
        name: 'Mixedbread Embed Large',
        provider: 'ollama',
        type: 'embedding',
        context_window: 512,
    },
];
